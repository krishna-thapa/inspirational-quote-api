## Sending Docker Logs to ElasticSearch and Kibana with FileBeat
- A self-hosted solution to store, search and analyze your logs using ELK stack (ElasticSearch, Logstash, Kibana)
- The Kibana interface let you very easily browse the logs previously stored in ElasticSearch
- To import the logs into ElasticSearch, can be achieved with the use of Logstash that supports numerous input plugins
- FileBeat is used as a replacement for Logstash. It was created because Logstash requires a JVM and tends to consume a lot of resources. Although FileBeat is simpler than Logstash, you can still do a lot of things with it.

### The setup meets the following requirements:
- All the docker container logs (available with the docker logs command) must be searchable in the Kibana interface.
- Even after being imported into ElasticSearch, the logs must remain available with the docker logs command.
- It should be as efficient as possible in terms of resource consumption (cpu and memory).
- It should be able to decode logs encoded in JSON.

### Architecture
1. Docker Daemon: Write the container logs in files and give additional information to FileBeat
2. Docker Log files: Logs file is written on the file system
3. ElasticSearch: Logs file are added to ES database by FileBeat
4. Kibana: A graphical interface to search the logs

## Run the Kibana and set up the index
- Run the docker compose: `docker-compose up`
- Goto: `http://localhost:5601`
- The first thing you have to do is to configure the ElasticSearch indices that can be displayed in Kibana.
  - Create index pattern, once the data are loaded in the ES index
  - Select all the indices that starts with `filebeat-*`, to include all the logs coming from FileBeat.
  - Define the field used as the log timestamp, should use `@timestamp`
  - Goto Kibana -> Discover 
  - You can filter with `container.name`, `message`, `json.level`, `json.logger` and more.
  - You can now visualize the logs generated by all the containers in a docker compose file, have to make use of filter 

## Removing old logs
- **Future work** Using [curator](https://www.elastic.co/guide/en/elasticsearch/client/curator/5.x/installation.html) as a cron job, see the resource article 
- For now, delete the old logs manually

```
# Truncate the logs in docker containers(doesn't delete the actual logs)
sudo sh -c "truncate -s 0 /var/lib/docker/containers/*/*-json.log"   

# Delete all the filebeat indexs in ES
curl -X DELETE http://127.0.0.1:9200/file\*   
curl -X GET http://127.0.0.1:9200/_cat/indices
```

## Dev tools
- In Kibana: Management -> Dev tools
```
# Get the all the indices in sorted name order
GET _cat/indices?pretty&s=i

# Get the content from the quotes index
GET quotes/_search?pretty

# Get all the alias
GET _alias

# Post new alias: See known errors point 3
POST /_aliases
{
  "actions": [
    {
      "add": {
        "index": "filebeat-7.10.2-2021.02.07",
        "alias": "ilebeat-7.10.2", 
        "is_write_index": true   
      }
    }
  ]
}
```

## **Future Fix** Enable Authentication in elasticsearch and kibana with docker environment variable
- [Enable Security in Elasticsearch using docker](https://stackoverflow.com/questions/50832249/enable-authentication-in-elasticsearch-with-docker-environment-variable)
- [Kibana user credentials with docker elk stack](https://stackoverflow.com/questions/55256995/how-to-setup-kibana-user-credentials-with-docker-elk-stack)
- Have to use [xpack security](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/get-started-enable-security.html?blade=kibanasecuritymessage) from Elastic search which is not free 

### Add the services using docker-compose file
- image for elasticsearch
- image for Kibana
- image for filebeat

### Known errors:
- [Filebeat docker Mac support](https://github.com/elastic/beats/issues/17310)
- [Filebeat.yml must be owned by the beat user (uid=0) or root](https://www.elastic.co/guide/en/beats/libbeat/5.3/config-file-permissions.html)
- Error regarding ` index.lifecycle.rollover_alias [filebeat-7.10.2] does not point to index [filebeat-7.10.2-2021.02.07]` -> [Solution](https://discuss.elastic.co/t/index-lifecycle-management-does-not-point-to-index-error/211513/4) -> Add a new alias in the missing index, not sure if there is some more automatic solution rather than manually adding alias on each time, see under Dev tools section

## Resources:
- [Elastic stack (ELK) on Docker](https://github.com/deviantony/docker-elk#configuration)
- [Sending Docker Logs to ElasticSearch and Kibana with FileBeat](https://www.sarulabs.com/post/5/2019-08-12/sending-docker-logs-to-elasticsearch-and-kibana-with-filebeat.html)